# ğŸš€ Apache Kafka with Python, Elasticsearch and Kibana Integration

This project demonstrates a complete data pipeline using Apache Kafka for message streaming, with Python producers and consumers, and integration with Elasticsearch and Kibana for data visualization.

## ğŸ“ Project Structure

```text
apache-kafka-kibana-elasticsearch\
    â”œâ”€â”€ consumer_to_elastic.py
    â”œâ”€â”€ consumidor_processamento.py
    â”œâ”€â”€ consumidor.py
    â”œâ”€â”€ dados_cambio.json
    â”œâ”€â”€ docker-compose.yml
    â”œâ”€â”€ produtor_api.py
    â”œâ”€â”€ produtor.py
    â””â”€â”€ README.md
```

- ğŸ“Š `produtor.py` - Simulates transaction data with different currencies
- ğŸ”„ `produtor_api.py` - Fetches real-time exchange rates from an external API
- ğŸ‘€ `consumidor.py` - Basic consumer that prints messages to console
- ğŸ’¾ `consumidor_processamento.py` - Consumer that saves messages to a JSON file
- ğŸ“ˆ `consumer_to_elastic.py` - Consumer that indexes messages into Elasticsearch
- ğŸ³ `docker-compose.yml` - Infrastructure setup with Kafka, Elasticsearch, and Kibana
- ğŸ“ `dados_cambio.json` - Storage file for exchange rate data

## ğŸ—ï¸ Infrastructure

The project uses Docker Compose to set up the following services:

- ğŸ“¨ Apache Kafka (v7.6.1)
- ğŸ” Zookeeper (v7.6.1)
- ğŸ” Elasticsearch (v8.5.0)
- ğŸ“Š Kibana (v8.5.0)

## ğŸ› ï¸ Prerequisites

- ğŸ³ Docker and Docker Compose
- ğŸ Python 3.x
- ğŸ“¦ pip (Python package manager)

## ğŸš€ Setup

1. Start the infrastructure:

```bash
docker compose up -d
```

2. Create a Python virtual environment:

```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. Install required Python packages:

```bash
pip install kafka-python requests
```

4. Create the Kafka topic:

```bash
docker exec -it c_kafka kafka-topics --create --topic transacoes \
    --bootstrap-server 0.0.0.0:9092 --partitions 1 --replication-factor 1
```

## ğŸ“œ Available Scripts

### ğŸ”„ Producers

1. ğŸ’³ Simulated Transaction Producer:

```bash
python produtor.py
```

- Generates mock transaction data with various currencies
- Sends data to 'transacoes' topic every 2 seconds

2. ğŸ“Š Real-time Exchange Rate Producer:

```bash
python produtor_api.py
```

- Fetches USD/EUR exchange rates from an external API
- Sends updates to 'transacoes' topic every 3 seconds

### ğŸ‘¥ Consumers

1. ğŸ–¥ï¸ Basic Consumer:

```bash
python consumidor.py
```

- Prints received messages to console
- Uses consumer group 'meu_grupo'

2. ğŸ’¾ Processing Consumer:

```bash
python consumidor_processamento.py
```

- Saves messages to `dados_cambio.json`
- Uses consumer group 'grupo_cambio'

3. ğŸ“Š Elasticsearch Consumer:

```bash
python consumer_to_elastic.py
```

- Indexes messages into Elasticsearch
- Uses consumer group 'grupo_elasticsearch'

## ğŸ“Š Monitoring

1. ğŸ“‹ List Kafka topics:

```bash
docker exec -it c_kafka kafka-topics --list --bootstrap-server 0.0.0.0:9092
```

2. Monitor messages in topic:

```bash
docker exec -it c_kafka kafka-console-consumer \
    --bootstrap-server 0.0.0.0:9092 --topic transacoes --from-beginning
```

3. Access Kibana:

- Open http://localhost:5601 in your browser
- Create an index pattern for 'transacoes'
- Use Discover to view incoming data

## ğŸ”Œ Service Ports

- ğŸ“¨ Kafka: 9092
- ğŸ” Zookeeper: 2181
- ğŸ” Elasticsearch: 9200
- ğŸ“Š Kibana: 5601
